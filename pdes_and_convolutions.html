<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MIT Parallel Computing and Scientific Machine Learning - 13&nbsp; PDEs, Convolutions, and the Mathematics of Locality</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./diffeq_machine_learning.html" rel="next">
<link href="./gpus.html" rel="prev">
<link href="./sciml-book-logo.svg" rel="icon" type="image/svg+xml">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./pdes_and_convolutions.html">Advanced Differential Equations</a></li><li class="breadcrumb-item"><a href="./pdes_and_convolutions.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">PDEs, Convolutions, and the Mathematics of Locality</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./sciml-book-logo.svg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MIT Parallel Computing and Scientific Machine Learning</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/jvaverka/SciMLBook" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./MIT-Parallel-Computing-and-Scientific-Machine-Learning.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./MIT-Parallel-Computing-and-Scientific-Machine-Learning.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Parallel Computing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optimize.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Optimizing Serial Code</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sciml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Scientific Machine Learning through Physics-Informed Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Parallel Computing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dynamical_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">How Loops Work, An Introduction to Discrete Dynamics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./parallelism_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Basics of Single Node Parallel Computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./styles_of_parallelism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">The Different Flavors of Parallelism</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discretizing_odes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Ordinary Differential Equations, Applications and Discretizations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Modern Approaches</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./automatic_differentiation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Forward-Mode Automatic Differentiation (AD) via High Dimensional Algebras</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stiff_odes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Solving Stiff Ordinary Differential Equations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation_identification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Basic Parameter Estimation, Reverse-Mode AD, and Inverse Problems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adjoints.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Differentiable Programming and Neural Differential Equations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Modern Architectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mpi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to MPI.jl</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gpus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">GPU programming</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Advanced Differential Equations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pdes_and_convolutions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">PDEs, Convolutions, and the Mathematics of Locality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diffeq_machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixing Differential Equations and Neural Networks for Physics-Informed Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probabilistic_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">From Optimization to Probabilistic Programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./global_sensitivity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Global Sensitivity Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./profiling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Code Profiling and Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Uncertainty Programming, Generalized Uncertainty Quantification</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#youtube-video" id="toc-youtube-video" class="nav-link active" data-scroll-target="#youtube-video"><span class="header-section-number">13.1</span> Youtube Video</a></li>
  <li><a href="#convolutional-neural-networks" id="toc-convolutional-neural-networks" class="nav-link" data-scroll-target="#convolutional-neural-networks"><span class="header-section-number">13.2</span> Convolutional Neural Networks</a></li>
  <li><a href="#discretizations-of-partial-differential-equations" id="toc-discretizations-of-partial-differential-equations" class="nav-link" data-scroll-target="#discretizations-of-partial-differential-equations"><span class="header-section-number">13.3</span> Discretizations of Partial Differential Equations</a>
  <ul class="collapse">
  <li><a href="#finite-difference-discretizations" id="toc-finite-difference-discretizations" class="nav-link" data-scroll-target="#finite-difference-discretizations"><span class="header-section-number">13.3.1</span> Finite Difference Discretizations</a></li>
  </ul></li>
  <li><a href="#representation-and-implementation-of-stencil-operations" id="toc-representation-and-implementation-of-stencil-operations" class="nav-link" data-scroll-target="#representation-and-implementation-of-stencil-operations"><span class="header-section-number">13.4</span> Representation and Implementation of Stencil Operations</a>
  <ul class="collapse">
  <li><a href="#stencil-operations-as-sparse-matrices" id="toc-stencil-operations-as-sparse-matrices" class="nav-link" data-scroll-target="#stencil-operations-as-sparse-matrices"><span class="header-section-number">13.4.1</span> Stencil Operations as Sparse Matrices</a></li>
  <li><a href="#implementation-via-stencil-compilers" id="toc-implementation-via-stencil-compilers" class="nav-link" data-scroll-target="#implementation-via-stencil-compilers"><span class="header-section-number">13.4.2</span> Implementation via Stencil Compilers</a></li>
  </ul></li>
  <li><a href="#cross-discipline-learning" id="toc-cross-discipline-learning" class="nav-link" data-scroll-target="#cross-discipline-learning"><span class="header-section-number">13.5</span> Cross-Discipline Learning</a>
  <ul class="collapse">
  <li><a href="#what-ml-can-learning-from-scicomp-stability-of-convolutional-rnns" id="toc-what-ml-can-learning-from-scicomp-stability-of-convolutional-rnns" class="nav-link" data-scroll-target="#what-ml-can-learning-from-scicomp-stability-of-convolutional-rnns"><span class="header-section-number">13.5.1</span> What ML can learning from SciComp: Stability of Convolutional RNNs</a></li>
  <li><a href="#what-scicomp-can-learn-from-ml-moderate-generalizations-to-partial-differential-equation-models" id="toc-what-scicomp-can-learn-from-ml-moderate-generalizations-to-partial-differential-equation-models" class="nav-link" data-scroll-target="#what-scicomp-can-learn-from-ml-moderate-generalizations-to-partial-differential-equation-models"><span class="header-section-number">13.5.2</span> What SciComp can learn from ML: Moderate Generalizations to Partial Differential Equation Models</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/jvaverka/SciMLBook/edit/main/pdes_and_convolutions.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/jvaverka/SciMLBook/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/jvaverka/SciMLBook/blob/main/pdes_and_convolutions.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">PDEs, Convolutions, and the Mathematics of Locality</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="youtube-video" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="youtube-video"><span class="header-section-number">13.1</span> <a href="https://youtu.be/apkyk8n0vBo">Youtube Video</a></h2>
<p>At this point we have identified how the worlds of machine learning and scientific computing collide by looking at the parameter estimation problem. Training neural networks is parameter estimation of a function <code>f</code> where <code>f</code> is a neural network. Backpropagation of a neural network is simply the adjoint problem for <code>f</code>, and it falls under the class of methods used in reverse-mode automatic differentiation. But this story also extends to structure. Recurrent neural networks are the Euler discretization of a continuous recurrent neural network, also known as a neural ordinary differential equation.</p>
<p>Given all of these relations, our next focus will be on the other class of commonly used neural networks: the <em>convolutional neural network</em> (CNN). It turns out that in this case there is also a clear analogue to convolutional neural networks in traditional scientific computing, and this is seen in discretizations of partial differential equations. To see this, we will first describe the convolution operation that is central to the CNN and see how this object naturally arises in numerical partial differential equations.</p>
</section>
<section id="convolutional-neural-networks" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="convolutional-neural-networks"><span class="header-section-number">13.2</span> Convolutional Neural Networks</h2>
<p>The purpose of a convolutional neural network is to be a network which makes use of the spatial structure of an image. An image is a 3-dimensional object: width, height, and 3 color channels. The convolutional operations keeps this structure intact and acts against this object is a 3-tensor. A convolutional layer is a function that applies a <em>stencil</em> to each point. This is illustrated by the following animation:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://miro.medium.com/max/526/1*GcI7G-JLAQiEoCON7xFbhg.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">convolution</figcaption>
</figure>
</div>
<p>This is the 2D stencil:</p>
<pre><code>1  0  1
0  1  0
1  0  1</code></pre>
<p>which is then applied to the matrix at each inner point to go from an NxNx3 matrix to an (N-2)x(N-2)x3 matrix.</p>
<p>Another operation used with convolutions is the <em>pooling layer</em>. For example, the <em>maxpool</em> layer is stencil which takes the maximum of the the value and its neighbor, and the <em>meanpool</em> takes the mean over the nearby values, i.e.&nbsp;it is equivalent to the stencil:</p>
<pre><code>1/9 1/9 1/9
1/9 1/9 1/9
1/9 1/9 1/9</code></pre>
<p>A convolutional neural network is then composed of layers of this form. We can express this mathematically by letting <span class="math inline">\(conv(x;S)\)</span> as the convolution of <span class="math inline">\(x\)</span> given a stencil <span class="math inline">\(S\)</span>. If we let <span class="math inline">\(dense(x;W,b,σ) = σ(W*x + b)\)</span> as a layer from a standard neural network, then deep convolutional neural networks are of forms like:</p>
<p><span class="math display">\[CNN(x) = dense(conv(maxpool(conv(x))))\]</span></p>
<p>which can be expressed in Flux.jl syntax as:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="fu">Chain</span>(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Conv</span>((<span class="fl">2</span>,<span class="fl">2</span>), <span class="fl">1</span><span class="op">=&gt;</span><span class="fl">16</span>, relu),</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  x <span class="op">-&gt;</span> <span class="fu">maxpool</span>(x, (<span class="fl">2</span>,<span class="fl">2</span>)),</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Conv</span>((<span class="fl">2</span>,<span class="fl">2</span>), <span class="fl">16</span><span class="op">=&gt;</span><span class="fl">8</span>, relu),</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  x <span class="op">-&gt;</span> <span class="fu">maxpool</span>(x, (<span class="fl">2</span>,<span class="fl">2</span>)),</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  x <span class="op">-&gt;</span> <span class="fu">reshape</span>(x, <span class="op">:</span>, <span class="fu">size</span>(x, <span class="fl">4</span>)),</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">Dense</span>(<span class="fl">288</span>, <span class="fl">10</span>), softmax) <span class="op">|&gt;</span> gpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="discretizations-of-partial-differential-equations" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="discretizations-of-partial-differential-equations"><span class="header-section-number">13.3</span> Discretizations of Partial Differential Equations</h2>
<p>Now let’s investigate discertizations of partial differential equations. A canonical differential equation to start with is the Poisson equation. This is the equation:</p>
<p><span class="math display">\[u_{xx} = f(x)\]</span></p>
<p>where here we have that subscripts correspond to partial derivatives, i.e. this syntax stands for the partial differential equation:</p>
<p><span class="math display">\[\frac{d^2u}{dx^2} = f(x)\]</span></p>
<p>In this case, <span class="math inline">\(f\)</span> is some given data and the goal is to find the <span class="math inline">\(u\)</span> that satisfies this equation. There are two ways this is generally done:</p>
<ol type="1">
<li>Expand out the derivative in terms of Taylor series approximations.</li>
<li>Expand out <span class="math inline">\(u\)</span> in terms of some function basis.</li>
</ol>
<section id="finite-difference-discretizations" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="finite-difference-discretizations"><span class="header-section-number">13.3.1</span> Finite Difference Discretizations</h3>
<p>Let’s start by looking at Taylor series approximations to the derivative. In this case, we will use what’s known as finite differences. The simplest finite difference approximation is known as the first order forward difference. This is commonly denoted as</p>
<p><span class="math display">\[\delta_{+}u=\frac{u(x+\Delta x)-u(x)}{\Delta x}\]</span></p>
<p>This looks like a derivative, and we think it’s a derivative as <span class="math inline">\(\Delta x\rightarrow 0\)</span>, but let’s show that this approximation is meaningful. Assume that <span class="math inline">\(u\)</span> is sufficiently nice. Then from a Taylor series we have that</p>
<p><span class="math display">\[u(x+\Delta x)=u(x)+\Delta xu^{\prime}(x)+\mathcal{O}(\Delta x^{2})\]</span></p>
<p>(here I write <span class="math inline">\(\left(\Delta x\right)^{2}\)</span> as <span class="math inline">\(\Delta x^{2}\)</span> out of convenience, note that those two terms are not necessarily the same). That term on the end is called “Big-O Notation”. What is means is that those terms are asymptotically like <span class="math inline">\(\Delta x^{2}\)</span>. If <span class="math inline">\(\Delta x\)</span> is small, then <span class="math inline">\(\Delta x^{2}\ll\Delta x\)</span> and so we can think of those terms as smaller than any of the terms we show in the expansion. By simplification notice that we get</p>
<p><span class="math display">\[\frac{u(x+\Delta x)-u(x)}{\Delta x}=u^{\prime}(x)+\mathcal{O}(\Delta x)\]</span> This means that <span class="math inline">\(\delta_{+}\)</span> is correct up to first order, where the <span class="math inline">\(\mathcal{O}(\Delta x)\)</span> portion that we dropped is the error. Thus <span class="math inline">\(\delta_{+}\)</span> is a first order approximation.</p>
<p>Notice that the same proof shows that the backwards difference,</p>
<p><span class="math display">\[\delta_{-}u=\frac{u(x)-u(x-\Delta x)}{\Delta x}\]</span></p>
<p>is first order.</p>
<section id="second-order-approximations-to-the-first-derivative" class="level4" data-number="13.3.1.1">
<h4 data-number="13.3.1.1" class="anchored" data-anchor-id="second-order-approximations-to-the-first-derivative"><span class="header-section-number">13.3.1.1</span> Second Order Approximations to the First Derivative</h4>
<p>Now let’s look at the following:</p>
<p><span class="math display">\[\delta_{0}u=\frac{u(x+\Delta x)-u(x-\Delta x)}{2\Delta x}.\]</span></p>
<p>The claim is this differencing scheme is second order. To show this, we once again turn to Taylor Series. Let’s do this for both terms:</p>
<p><span class="math display">\[u(x+\Delta x) =u(x)+\Delta xu^{\prime}(x)+\frac{\Delta x^{2}}{2}u^{\prime\prime}(x)+\mathcal{O}(\Delta x^{3})\]</span> <span class="math display">\[u(x-\Delta x) =u(x)-\Delta xu^{\prime}(x)+\frac{\Delta x^{2}}{2}u^{\prime\prime}(x)+\mathcal{O}(\Delta x^{3})\]</span></p>
<p>Now we subtract the two:</p>
<p><span class="math display">\[u(x+\Delta x)-u(x-\Delta x)=2\Delta xu^{\prime}(x)+\mathcal{O}(\Delta x^{3})\]</span></p>
<p>and thus we move tems around to get</p>
<p><span class="math display">\[\delta_{0}u=\frac{u(x+\Delta x)-u(x-\Delta x)}{2\Delta x}=u^{\prime}(x)+\mathcal{O}\left(\Delta x^{2}\right)\]</span></p>
<p>What does this improvement mean? Let’s say we go from <span class="math inline">\(\Delta x\)</span> to <span class="math inline">\(\frac{\Delta x}{2}\)</span>. Then while the error from the first order method is around <span class="math inline">\(\frac{1}{2}\)</span> the original error, the error from the central differencing method is <span class="math inline">\(\frac{1}{4}\)</span> the original error! When trying to get an accurate solution, this quadratic reduction can make quite a difference in the number of required points.</p>
</section>
<section id="second-derivative-central-difference" class="level4" data-number="13.3.1.2">
<h4 data-number="13.3.1.2" class="anchored" data-anchor-id="second-derivative-central-difference"><span class="header-section-number">13.3.1.2</span> Second Derivative Central Difference</h4>
<p>Now we want a second derivative approximation. Let’s show the classic central difference formula for the second derivative:</p>
<p><span class="math display">\[\delta_{0}^{2}u=\frac{u(x+\Delta x)-2u(x)+u(x-\Delta x)}{\Delta x^{2}}\]</span></p>
<p>is second order. To do so, we expand out the two terms:</p>
<p><span class="math display">\[u(x+\Delta x) =u(x)+\Delta xu^{\prime}(x)+\frac{\Delta x^{2}}{2}u^{\prime\prime}(x)+\frac{\Delta x^{3}}{6}u^{\prime\prime\prime}(x)+\mathcal{O}\left(\Delta x^{4}\right)\]</span> <span class="math display">\[u(x-\Delta x) =u(x)-\Delta xu^{\prime}(x)+\frac{\Delta x^{2}}{2}u^{\prime\prime}(x)-\frac{\Delta x^{3}}{6}u^{\prime\prime\prime}(x)+\mathcal{O}\left(\Delta x^{4}\right)\]</span></p>
<p>and now plug it in. It’s clear the <span class="math inline">\(u(x)\)</span> cancels out. The opposite signs makes <span class="math inline">\(u^{\prime}(x)\)</span> cancel out, and then the same signs and cancellation makes the <span class="math inline">\(u^{\prime\prime}\)</span> term have a coefficient of 1. But, the opposite signs makes the <span class="math inline">\(u^{\prime\prime\prime}\)</span> term cancel out. Thus when we simplify and divide by <span class="math inline">\(\Delta x^{2}\)</span> we get</p>
<p><span class="math display">\[\frac{u(x+\Delta x)-2u(x)+u(x-\Delta x)}{\Delta x^{2}}=u^{\prime\prime}(x)+\mathcal{O}\left(\Delta x^{2}\right).\]</span></p>
</section>
<section id="finite-differencing-from-polynomial-interpolation" class="level4" data-number="13.3.1.3">
<h4 data-number="13.3.1.3" class="anchored" data-anchor-id="finite-differencing-from-polynomial-interpolation"><span class="header-section-number">13.3.1.3</span> Finite Differencing from Polynomial Interpolation</h4>
<p>Finite differencing can also be derived from polynomial interpolation. Draw a line between two points. What is the approximation for the first derivative?</p>
<p><span class="math display">\[\delta_{+}u=\frac{u(x+\Delta x)-u(x)}{\Delta x}\]</span></p>
<p>Now draw a quadratic through three points. i.e., given <span class="math inline">\(u_{1}\)</span>, <span class="math inline">\(u_{2}\)</span>, and <span class="math inline">\(u_{3}\)</span> at <span class="math inline">\(x=0\)</span>, <span class="math inline">\(\Delta x\)</span>, <span class="math inline">\(2\Delta x\)</span>, we want to find the interpolating polynomial</p>
<p><span class="math display">\[g(x)=a_{1}x^{2}+a_{2}x+a_{3}\]</span>.</p>
<p>Setting <span class="math inline">\(g(0)=u_{1}\)</span>, <span class="math inline">\(g(\Delta x)=u_{2}\)</span>, and <span class="math inline">\(g(2\Delta x)=u_{3}\)</span>, we get the following relations:</p>
<p><span class="math display">\[u_{1} =g(0)=a_{3}\]</span> <span class="math display">\[u_{2} =g(\Delta x)=a_{1}\Delta x^{2}+a_{2}\Delta x+a_{3}\]</span> <span class="math display">\[u_{3} =g(2\Delta x)=4a_{1}\Delta x^{2}+2a_{2}\Delta x+a_{3}\]</span></p>
<p>which when we write in matrix form is:</p>
<p><span class="math display">\[\left(\begin{array}{ccc}
0 &amp; 0 &amp; 1\\
\Delta x^{2} &amp; \Delta x &amp; 1\\
4\Delta x^{2} &amp; 2\Delta x &amp; 1
\end{array}\right)\left(\begin{array}{c}
a_{1}\\
a_{2}\\
a_{3}
\end{array}\right)=\left(\begin{array}{c}
u_{1}\\
u_{2}\\
u_{3}
\end{array}\right)\]</span></p>
<p>and thus we can invert the matrix to get the a’s:</p>
<p><span class="math display">\[a_{1} =\frac{u_{3}-2u_{2}+u_{1}}{2\Delta x^{2}}\]</span> <span class="math display">\[a_{2} =\frac{-u_{3}+4u_{2}-3u_{1}}{2\Delta x}\]</span> <span class="math display">\[a_{3} =u_{1}\text{ or }g(x)=\frac{u_{3}-2u_{2}-u_{1}}{2\Delta x^{2}}x^{2}+\frac{-u_{3}+4u_{2}-3u_{1}}{2\Delta x}x+u_{1}\]</span></p>
<p>Now we can get derivative approximations from this. Notice for example that</p>
<p><span class="math display">\[g^{\prime}(x)=\frac{u_{3}-2u_{2}+u_{1}}{\Delta x^{2}}x+\frac{-u_{3}+4u_{2}-3u_{1}}{2\Delta x}\]</span></p>
<p>Now what’s the derivative at the middle point?</p>
<p><span class="math display">\[g^{\prime}\left(\Delta x\right)=\frac{u_{3}-2u_{2}+u_{1}}{\Delta x}+\frac{-u_{3}+4u_{2}-3u_{1}}{2\Delta x}=\frac{u_{3}-u_{1}}{2\Delta x}.\]</span></p>
<p>And now check</p>
<p><span class="math display">\[g^{\prime\prime}(\Delta x)=\frac{u_{3}-2u_{2}+u_{1}}{\Delta x^{2}}\]</span> which is the central derivative formula. This gives a systematic way of deriving higher order finite differencing formulas. In fact, this formulation allows one to derive finite difference formulae for non-evenly spaced grids as well! The algorithm which automatically generates stencils from the interpolating polynomial forms is the Fornberg algorithm.</p>
</section>
<section id="multidimensional-finite-difference-operations" class="level4" data-number="13.3.1.4">
<h4 data-number="13.3.1.4" class="anchored" data-anchor-id="multidimensional-finite-difference-operations"><span class="header-section-number">13.3.1.4</span> Multidimensional Finite Difference Operations</h4>
<p>Now let’s look at the multidimensional Poisson equation, commonly written as:</p>
<p><span class="math display">\[\Delta u = f(x,y)\]</span></p>
<p>where <span class="math inline">\(\Delta u = u_{xx} + u_{yy}\)</span>. Using the logic of the previous sections, we can approximate the two derivatives to have:</p>
<p><span class="math display">\[\frac{u(x+\Delta x,y)-2u(x,y)+u(x-\Delta x,y)}{\Delta x^{2}} + \frac{u(x,y+\Delta y)-2u(x,y)+u(x-x,y-\Delta y)}{\Delta y^{2}}=u^{\prime\prime}(x)+\mathcal{O}\left(\Delta x^{2}\right) + \mathcal{O}\left(\Delta y^{2}\right).\]</span></p>
<p>Notice that this is the stencil operation:</p>
<pre><code>0  1 0
1 -4 1
0  1 0</code></pre>
<p>This means that <strong>derivative discretizations are stencil or convolutional operations</strong>.</p>
</section>
</section>
</section>
<section id="representation-and-implementation-of-stencil-operations" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="representation-and-implementation-of-stencil-operations"><span class="header-section-number">13.4</span> Representation and Implementation of Stencil Operations</h2>
<section id="stencil-operations-as-sparse-matrices" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="stencil-operations-as-sparse-matrices"><span class="header-section-number">13.4.1</span> Stencil Operations as Sparse Matrices</h3>
<p>Stencil operations are linear operators, i.e.&nbsp;<span class="math inline">\(S[x+\alpha y] = S[x] + \alpha S[y]\)</span> for any sufficiently nice stencil operation <span class="math inline">\(S\)</span> (note “sufficiently nice”: there is a “stencil” operation mentioned in the convolutional neural networks section which was not linear: which operation was it?). Now we write these operators as matrices. Notice that for the vector:</p>
<p><span class="math display">\[U=\left(\begin{array}{c}
u_{1}\\
\vdots\\
u_{n}
\end{array}\right),\]</span> we have that</p>
<p><span class="math display">\[\delta_{+}U=\left(\begin{array}{c}
u_{2}-u_{1}\\
\vdots\\
u_{n}-u_{n-1}
\end{array}\right)\]</span></p>
<p>and so</p>
<p><span class="math display">\[\delta_{+}=\left(\begin{array}{ccccc}
-1 &amp; 1\\
&amp; -1 &amp; 1\\
&amp;  &amp; \ddots &amp; \ddots\\
&amp;  &amp;  &amp; -1 &amp; 1
\end{array}\right)\]</span></p>
<p>We can do the same to understand the other operators. But notice something: this operator isn’t square! In order for this to be square, in order to know what happens at the endpoint, we need to know the boundary conditions. I.e., an assumption on the value or derivative at <span class="math inline">\(u(0)\)</span> or <span class="math inline">\(u(1)\)</span> is required in order to get the first/last rows of the matrix!</p>
<p>Similarly, <span class="math inline">\(\delta_{0}^{2}\)</span> can be represented as the tridiagonal matrix of <code>[1 -2 1]</code>, also known as the Strang matrix.</p>
<p>Now let’s think about the higher dimensional forms as a vector, i.e.&nbsp;<code>vec(u)</code>. In this case, what is the matrix <code>A</code> for which <code>reshape(A*vec(u),size(u)...)</code> performs the higher dimensional Laplacian, i.e.&nbsp;<span class="math inline">\(u_{xx} + u_{yy}\)</span>? The answer is that it discretizes via Kronecker products to:</p>
<p><span class="math display">\[A=I_{y}\otimes A_{x}+A_{y}\otimes I_{x}\]</span></p>
<p>or:</p>
<p><span class="math display">\[\frac{\partial^{2}}{\partial x^{2}}=\left(\begin{array}{cccc}
A_{x}\\
&amp; A_{x}\\
&amp;  &amp; \ddots\\
&amp;  &amp;  &amp; A_{x}
\end{array}\right)\]</span></p>
<p>and</p>
<p><span class="math display">\[\frac{\partial^{2}}{\partial y^{2}}=\left(\begin{array}{cccc}
-2I_{x} &amp; I_{x}\\
I_{x} &amp; -2I_{x} &amp; I_{x}\\
&amp;  &amp; \ddots\\
\\
\end{array}\right)\]</span></p>
<p>To see why this is the case, understand it again as the stencil operation</p>
<pre><code>0  1 0
1 -4 1
0  1 0</code></pre>
<p>In this operation, at a point you still use the up and down neighbors, and thus this has a tridiagonal form since those are the immediate neighbors, but the next <span class="math inline">\(y\)</span> value is <span class="math inline">\(N\)</span> over, so this is where the block tridiagonal form comes for the stencil in the <span class="math inline">\(y\)</span> terms. When these are added together one receives the appropriate matrix. The Kronecker product effectively encodes this “N over” behavior. It also readily generalizes to <span class="math inline">\(N\)</span> dimensions. To see this for 3-dimensional Laplacians, <span class="math inline">\(u_{xx} + u_{yy} + u_{zz}\)</span>, notice that</p>
<p><span class="math display">\[A=I_z \otimes I_{y}\otimes A_{x} + I_z \otimes A_{y}\otimes I_{x} + A_z \otimes I_y \otimes I_x\]</span></p>
<p>using the same reasoning about “N” over and “N^2 over”, and from this formulation it’s clear how to generalize to arbitrary dimensions.</p>
<p>We note that there is an alternative representation as well for 2D forms. We can represent them with left and right matrix operations. When <span class="math inline">\(u\)</span> is represented as a matrix, notice that</p>
<p><span class="math display">\[A(u) = A_y u + u A_x\]</span></p>
<p>where <span class="math inline">\(A_y\)</span> and <span class="math inline">\(A_x\)</span> are both the <code>[1 -2 1]</code> 1D tridiagonal stencil matrix, but by right multiplying it’s occurring along the columns and left multiplying occurs along the rows. This then gives a semi-dense formulation of the stencil operation.</p>
</section>
<section id="implementation-via-stencil-compilers" class="level3" data-number="13.4.2">
<h3 data-number="13.4.2" class="anchored" data-anchor-id="implementation-via-stencil-compilers"><span class="header-section-number">13.4.2</span> Implementation via Stencil Compilers</h3>
<p>Sparse matrix implementations of stencils are fairly inefficient given the way that sparse matrices are represented (lists of (i,j,v) pairs, which are then compressed into CSR or CSC formats). However, it moves in the right direction by noticing that the operation</p>
<pre><code>u[i+1,j] + u[i,j+1] + u[i-1,j] + u[i,j-1] - 4u[i,j]</code></pre>
<p>is an inefficient way to walk through the data. The reason is because <code>u[i,j+1]</code> is using values that are far away from <code>u[i,j]</code>, and thus they may not necessarily be in the cache.</p>
<p>Thus what is generally used is a <em>stencil compiler</em> which generates functions for stencil operations. These work by dividing the tensor into blocks on which the stencil is applied, where the blocks are small enough to allow the cache lines to fit the future points. This is a very deep computational topic that is beyond the scope of this course. Note one of the main reasons why NVIDA’s CUDA dominates machine learning is because of its <code>cudnn</code> library, which is a very efficient GPU stencil computation library that is specifically tuned to NVIDIA’s GPUs.</p>
</section>
</section>
<section id="cross-discipline-learning" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="cross-discipline-learning"><span class="header-section-number">13.5</span> Cross-Discipline Learning</h2>
<p>Given these relations, there is a lot each of the disciplines can learn from one another about stencil computations.</p>
<section id="what-ml-can-learning-from-scicomp-stability-of-convolutional-rnns" class="level3" data-number="13.5.1">
<h3 data-number="13.5.1" class="anchored" data-anchor-id="what-ml-can-learning-from-scicomp-stability-of-convolutional-rnns"><span class="header-section-number">13.5.1</span> What ML can learning from SciComp: Stability of Convolutional RNNs</h3>
<p>Stability of time-dependent partial differential equations is a long-known problem. Stability of an RNN defined by stencil computations is then stability of Euler discretizations of PDEs. Let’s take a look at Von Neumann analysis of PDE stability.</p>
<p>Let’s look at the error update equation. Write</p>
<p><span class="math display">\[e_{i}^{n}=u(x_{j},t_{n})-u_{j}^{n}\]</span></p>
<p>For <span class="math inline">\(e_{i}^{n}\)</span>, as before, plug it in, add and subtract <span class="math inline">\(u(x_{j},t^{n})=u_{j}^{n}\)</span>, and then we get</p>
<p><span class="math display">\[e_{i}^{n+1}=e_{i}^{n}+\mu\left(e_{i+1}^{n}-2e_{i}^{n}+e_{i-1}^{n}\right)+\Delta t\tau_{i}^{n}\]</span></p>
<p>where</p>
<p><span class="math display">\[\tau_{i}^{n}\sim\mathcal{O}(\Delta t)+\mathcal{O}(\Delta x^{2}).\]</span></p>
<p>Stability requires that the homogenous equation goes to zero. Another way of saying that is that the propagation of errors has errors decrease their influence over time. Thus we look at:</p>
<p><span class="math display">\[e_{i}^{n+1}   =e_{i}^{n}+\mu\left(e_{i+1}^{n}-2e_{i}^{n}+e_{i-1}^{n}\right) =\left(1-2\mu\right)e_{i}^{n}+\mu e_{i+1}^{n}+\mu e_{i-1}^{n}\]</span></p>
<p>A necessary condition for decreasing is then for all coefficients to be positive</p>
<p><span class="math display">\[1-2\mu\geq0\]</span> or</p>
<p><span class="math display">\[\mu\leq\frac{1}{2}\]</span></p>
<p>A more satisfying way may be to look at the generated ODE</p>
<p><span class="math display">\[u^{\prime}=Au\]</span></p>
<p>where A is the matrix <span class="math inline">\(\left[\mu,1-2\mu,\mu\right].\)</span></p>
<p>But finding the maximum eigenvalue is non-trivial. But for linear PDEs, one nice way to analyze the stability directly is to use the Fourier mode decomposition. This is known as Van Neumann stability analysis. To do this, decompose <span class="math inline">\(U\)</span> into the Fourier modes:</p>
<p><span class="math display">\[U(x,t)=\sum_{k}\hat{U}(t)e^{ikx}\]</span></p>
<p>Since</p>
<p><span class="math display">\[x_{j}=j\Delta x,\]</span></p>
<p>we can write this out as</p>
<p><span class="math display">\[U_{j}^{n}=\hat{U}^{n}e^{ikj\Delta x}\]</span></p>
<p>and then plugging this into the FTCS scheme we get</p>
<p><span class="math display">\[\frac{\hat{U}^{n+1}e^{ikj\Delta x}-\hat{U}^{n}e^{ikj\Delta x}}{\Delta t}=\frac{\hat{U}^{n}e^{ik(j+1)\Delta x}-2\hat{U}^{n}e^{ikj\Delta x}+\hat{U}^{n}e^{ik(j-1)\Delta x}}{\Delta x^{2}}\]</span></p>
<p>Let G be the growth factor, defined as</p>
<p><span class="math display">\[G=\frac{\hat{U}^{n+1}}{\hat{U}^{n}}\]</span></p>
<p>and thus after cancelling we get</p>
<p><span class="math display">\[\frac{G-1}{\Delta t}=\frac{e^{ik\Delta x}-2+e^{-ik\Delta x}}{\Delta x^{2}}\]</span></p>
<p>Since</p>
<p><span class="math display">\[e^{ik\Delta x}+e^{-ik\Delta x}=2\cos\left(k\Delta x\right),\]</span></p>
<p>then we get</p>
<p><span class="math display">\[G=1-\mu\left(2\cos\left(k\Delta x\right)-2\right)\]</span></p>
<p>and using the half angle formula</p>
<p><span class="math display">\[G=1-4\mu\sin^{2}\left(\frac{k\Delta x}{2}\right)\]</span></p>
<p>In order to be stable, we require</p>
<p><span class="math display">\[\left|G\right|\leq1,\]</span></p>
<p>which means</p>
<p><span class="math display">\[-1\leq1-4\mu\sin^{2}\left(\frac{k\Delta x}{2}\right)\leq1 \mu&gt;0\]</span></p>
<p>and so <span class="math inline">\(\leq1\)</span> is simple. Since <span class="math inline">\(\sin^{2}(x)\leq1\)</span>, then we can simplify this to</p>
<p><span class="math display">\[-1\leq1-4\mu\]</span></p>
<p>and thus <span class="math inline">\(\mu\leq\frac{1}{2}\)</span>. With backwards Euler we get</p>
<p><span class="math display">\[\frac{G-1}{\Delta t}=\frac{G}{\Delta x^{2}}\left(e^{ik\Delta x}-2+e^{-ik\Delta x}\right)\]</span></p>
<p>and thus get</p>
<p><span class="math display">\[G+4G\mu\sin^{2}\left(\frac{k\Delta x}{2}\right)=1\]</span></p>
<p>and thus</p>
<p><span class="math display">\[G=\frac{1}{1+4\mu\sin^{2}\left(\frac{k\Delta x}{2}\right)}\leq1.\]</span></p>
</section>
<section id="what-scicomp-can-learn-from-ml-moderate-generalizations-to-partial-differential-equation-models" class="level3" data-number="13.5.2">
<h3 data-number="13.5.2" class="anchored" data-anchor-id="what-scicomp-can-learn-from-ml-moderate-generalizations-to-partial-differential-equation-models"><span class="header-section-number">13.5.2</span> What SciComp can learn from ML: Moderate Generalizations to Partial Differential Equation Models</h3>
<p>Instead of using</p>
<p><span class="math display">\[\Delta u = f\]</span></p>
<p>we can start with</p>
<p><span class="math display">\[S[u] = f\]</span></p>
<p>a stencil computation, predefined to match a known partial differential equation operator, and then <em>transfer learn</em> the stencil to better match data. This is an approach which is starting to move down the lines of <em>physics-informed machine learning</em> that will be further explored in future lectures.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./gpus.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">GPU programming</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./diffeq_machine_learning.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mixing Differential Equations and Neural Networks for Physics-Informed Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>